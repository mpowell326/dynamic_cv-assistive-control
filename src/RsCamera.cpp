/* -------------------------------------------------------------
    src/RsCamera.cpp        

    Purpose:    Interface to realsense camera for streaming and
                retrieving frames providing them in cv::Mat a
                format.
    
    Created:    Dec 2016
    Author:     Morgan
   ------------------------------------------------------------- */

#include "RsCamera.hpp"


#define HDR_ENABLED false


std::vector<uint16_t> enabled_streams = {   (uint16_t)rs::stream::depth                           ,  ///< Native stream of depth data produced by RealSense device
                                            (uint16_t)rs::stream::color                           ,  ///< Native stream of color data captured by RealSense device
                                            (uint16_t)rs::stream::infrared                        ,  ///< Native stream of infrared data captured by RealSense device
                                            (uint16_t)rs::stream::infrared2                       ,  ///< Native stream of infrared data captured from a second viewpoint by RealSense device
                                            // (uint16_t)rs::stream::fisheye                         ,
                                            // (uint16_t)rs::stream::points                          ,  ///< Synthetic stream containing point cloud data generated by deprojecting the depth image
                                            // (uint16_t)rs::stream::rectified_color                 ,  ///< Synthetic stream containing undistorted color data with no extrinsic rotation from the depth stream
                                            // (uint16_t)rs::stream::color_aligned_to_depth          ,  ///< Synthetic stream containing color data but sharing intrinsic of depth stream
                                            // (uint16_t)rs::stream::infrared2_aligned_to_depth      ,  ///< Synthetic stream containing second viewpoint infrared data but sharing intrinsic of depth stream
                                            // (uint16_t)rs::stream::depth_aligned_to_color          ,  ///< Synthetic stream containing depth data but sharing intrinsic of color stream
                                            // (uint16_t)rs::stream::depth_aligned_to_rectified_color, ///< Synthetic stream containing depth data but sharing intrinsic of rectified color stream
                                            // (uint16_t)rs::stream::depth_aligned_to_infrared2      ,  ///< Synthetic stream containing depth data but sharing intrinsic of second viewpoint infrared stream
                                        };

std::vector<uint16_t> displayed_streams = { (uint16_t)rs::stream::depth                           ,  ///< Native stream of depth data produced by RealSense device
                                            (uint16_t)rs::stream::color                           ,  ///< Native stream of color data captured by RealSense device
                                            // (uint16_t)rs::stream::infrared                        ,  ///< Native stream of infrared data captured by RealSense device
                                            // (uint16_t)rs::stream::infrared2                       ,  ///< Native stream of infrared data captured from a second viewpoint by RealSense device
                                            // (uint16_t)rs::stream::fisheye                         ,
                                            // (uint16_t)rs::stream::points                          ,  ///< Synthetic stream containing point cloud data generated by deprojecting the depth image
                                            // (uint16_t)rs::stream::rectified_color                 ,  ///< Synthetic stream containing undistorted color data with no extrinsic rotation from the depth stream
                                            // (uint16_t)rs::stream::color_aligned_to_depth          ,  ///< Synthetic stream containing color data but sharing intrinsic of depth stream
                                            // (uint16_t)rs::stream::infrared2_aligned_to_depth      ,  ///< Synthetic stream containing second viewpoint infrared data but sharing intrinsic of depth stream
                                            // (uint16_t)rs::stream::depth_aligned_to_color          ,  ///< Synthetic stream containing depth data but sharing intrinsic of color stream
                                            // (uint16_t)rs::stream::depth_aligned_to_rectified_color, ///< Synthetic stream containing depth data but sharing intrinsic of rectified color stream
                                            // (uint16_t)rs::stream::depth_aligned_to_infrared2      ,  ///< Synthetic stream containing depth data but sharing intrinsic of second viewpoint infrared stream
                                        };


// r200_lr_auto_exposure_enabled                   , /**< Enables / disables R200 auto-exposure. This will affect both IR and depth image.*/
// r200_lr_gain                                    , /**< IR image gain*/
// r200_lr_exposure                                , /**< This control allows manual adjustment of the exposure time value for the L/R imagers*/
// r200_emitter_enabled                            , /**< Enables / disables R200 emitter*/
// r200_depth_units                                , /**< Micrometers per increment in integer depth values, 1000 is default (mm scale). Set before streaming*/
// r200_depth_clamp_min                            , /**< Minimum depth in current depth units that will be output. Any values less than ‘Min Depth’ will be mapped to 0 during the conversion between disparity and depth. Set before streaming*/
// r200_depth_clamp_max                            , /**< Maximum depth in current depth units that will be output. Any values greater than ‘Max Depth’ will be mapped to 0 during the conversion between disparity and depth. Set before streaming*/
// r200_disparity_multiplier                       , /**< The disparity scale factor used when in disparity output mode. Can only be set before streaming*/
// r200_disparity_shift                            , /**< {0 - 512}. Can only be set before streaming starts*/
// r200_auto_exposure_mean_intensity_set_point     , /**< (Requires LR-Auto-Exposure ON) Mean intensity set point*/
// r200_auto_exposure_bright_ratio_set_point       , /**< (Requires LR-Auto-Exposure ON) Bright ratio set point*/
// r200_auto_exposure_kp_gain                      , /**< (Requires LR-Auto-Exposure ON) Kp Gain*/
// r200_auto_exposure_kp_exposure                  , /**< (Requires LR-Auto-Exposure ON) Kp Exposure*/
// r200_auto_exposure_kp_dark_threshold            , /**< (Requires LR-Auto-Exposure ON) Kp Dark Threshold*/
// r200_auto_exposure_top_edge                     , /**< (Requires LR-Auto-Exposure ON) Auto-Exposure region-of-interest top edge (in pixels)*/
// r200_auto_exposure_bottom_edge                  , /**< (Requires LR-Auto-Exposure ON) Auto-Exposure region-of-interest bottom edge (in pixels)*/
// r200_auto_exposure_left_edge                    , /**< (Requires LR-Auto-Exposure ON) Auto-Exposure region-of-interest left edge (in pixels)*/
// r200_auto_exposure_right_edge                   , /**< (Requires LR-Auto-Exposure ON) Auto-Exposure region-of-interest right edge (in pixels)*/
// r200_depth_control_estimate_median_decrement    , /**< Value to subtract when estimating the median of the correlation surface*/
// r200_depth_control_estimate_median_increment    , /**< Value to add when estimating the median of the correlation surface*/
// r200_depth_control_median_threshold             , /**< A threshold by how much the winning score must beat the median*/
// r200_depth_control_score_minimum_threshold      , /**< The minimum correlation score that is considered acceptable*/
// r200_depth_control_score_maximum_threshold      , /**< The maximum correlation score that is considered acceptable*/
// r200_depth_control_texture_count_threshold      , /**< A parameter for determining whether the texture in the region is sufficient to justify a depth result*/
// r200_depth_control_texture_difference_threshold , /**< A parameter for determining whether the texture in the region is sufficient to justify a depth result*/
// r200_depth_control_second_peak_threshold        , /**< A threshold on how much the minimum correlation score must differ from the next best score*/
// r200_depth_control_neighbor_threshold           , /**< Neighbor threshold value for depth calculation*/
// r200_depth_control_lr_threshold                 , /**< Left-Right threshold value for depth calculation*/



RsCamera::RsCamera(){}


void RsCamera::setParams()
{
    /* Get Rs options */
    cout<<"Option"<<endl;
    double min, max, step, current;
    _device->get_option_range(rs::option::r200_lr_gain, min, max, step, current);
    cout<<"Min: "<<min<<", Max: "<<max<<", Step: "<<step<<", Default: "<<current<<endl;

    
    /* Set Rs options */
    // rs::apply_depth_control_preset(_device, 3);   
    // _device->set_option(rs::option::r200_emitter_enabled,1);
    // _device->set_option(rs::option::r200_lr_gain,2000);
    // _device->set_option(rs::option::r200_depth_units,10000);

    // _device->set_option(rs::option::r200_lr_auto_exposure_enabled,1);
    // _device->set_option(rs::option::r200_depth_clamp_min,5);

    /* Settings for outdoors:
    referenced from: https://github.com/IntelRealSense/librealsense/issues/208
    */
    // _device->set_option(rs::option::color_backlight_compensation,0);
    // _device->set_option(rs::option::color_brightness, 62);
    // _device->set_option(rs::option::color_contrast, 38 );
    // _device->set_option(rs::option::color_enable_auto_white_balance, 0 );
    // _device->set_option(rs::option::color_gain, 88 );
    // _device->set_option(rs::option::color_gamma, 180 );
    // _device->set_option(rs::option::color_hue, -1018 );
    // _device->set_option(rs::option::color_saturation, 87 );
    // _device->set_option(rs::option::color_sharpness, 7 );
    // _device->set_option(rs::option::color_white_balance, 2987 );
    // _device->set_option(rs::option::r200_lr_auto_exposure_enabled, 1); 
    // _device->set_option(rs::option::r200_auto_exposure_bottom_edge, 239); 
    // _device->set_option(rs::option::r200_auto_exposure_left_edge, 0);
    // _device->set_option(rs::option::r200_auto_exposure_right_edge, 319); 
    // _device->set_option(rs::option::r200_auto_exposure_top_edge, 0); 
    // _device->set_option(rs::option::r200_emitter_enabled, 1);
    // _device->set_option(rs::option::r200_lr_exposure, 7); 
    // _device->set_option(rs::option::r200_lr_gain, 100);




    _device->set_option(rs::option::r200_lr_auto_exposure_enabled                   , 1); 
    _device->set_option(rs::option::r200_lr_gain                                    , 100);
    _device->set_option(rs::option::r200_lr_exposure                                , 164); 
    _device->set_option(rs::option::r200_emitter_enabled                            , 1);
    _device->set_option(rs::option::r200_depth_units                                , 1000);
    _device->set_option(rs::option::r200_depth_control_estimate_median_decrement    , 43);
    _device->set_option(rs::option::r200_depth_control_estimate_median_increment    , 0);
    _device->set_option(rs::option::r200_depth_control_median_threshold             , 0);
    _device->set_option(rs::option::r200_depth_control_score_minimum_threshold      , 0);
    _device->set_option(rs::option::r200_depth_control_score_maximum_threshold      , 555);
    _device->set_option(rs::option::r200_depth_control_texture_count_threshold      , 6);
    _device->set_option(rs::option::r200_depth_control_texture_difference_threshold , 14);
    _device->set_option(rs::option::r200_depth_control_second_peak_threshold        , 19);
    _device->set_option(rs::option::r200_depth_control_neighbor_threshold           , 0);
    _device->set_option(rs::option::r200_depth_control_lr_threshold                 , 9); 

}

bool RsCamera::startStreaming()
{
    bool success = false;


    printf("There are %d connected RealSense devices.\n", _rsCtx.get_device_count());
    if(_rsCtx.get_device_count() != 0)
    {
        _device = _rsCtx.get_device(0);
        // cout<<enabled_streams.size()<<endl;
        streams_mat.resize(12);

        printf("\nUsing device 0, an %s\n", _device->get_name());
        printf("    Serial number: %s\n", _device->get_serial());
        printf("    Firmware version: %s\n", _device->get_firmware_version());


        /* Configure all streams */
        rs::preset stream_preset = rs::preset::highest_framerate;   //best_quality, largest_image, highest_framerate

        // _device->enable_stream(rs::stream::depth, 0, 0, rs::format::z16, fps, rs::output_buffer_format::native);
        // _device->enable_stream(rs::stream::color, frameWidth, frameHeight, rs::format::rgb8, fps, rs::output_buffer_format::native);
        // _device->enable_stream(rs::stream::infrared, 0, 0, rs::format::y8, fps, rs::output_buffer_format::native);
        // if (_device->supports(rs::capabilities::infrared2))
        //     _device->enable_stream(rs::stream::infrared2, 0, 0, rs::format::y8, fps, rs::output_buffer_format::native);

        _device->enable_stream(rs::stream::depth, stream_preset);
        _device->enable_stream(rs::stream::color, stream_preset);
        _device->enable_stream(rs::stream::infrared, stream_preset);
        if (_device->supports(rs::capabilities::infrared2))
            _device->enable_stream(rs::stream::infrared2, stream_preset);

        
        setParams();
        _device->start();

        success = true;
    }
    return success;
}

void RsCamera::stopStreaming()
{
    _device->stop();

    for (auto i : enabled_streams)
    {
        if (_device->is_stream_enabled((rs::stream)i))
            _device->disable_stream((rs::stream)i);
    }
}


void RsCamera::getNextFrame()
{
    const void * rawFrame;
    const double timestamp = _device->get_frame_timestamp(rs::stream::color);


    _device->wait_for_frames();

    if(timestamp != last_timestamp)
    {

        for (auto i : enabled_streams)
        {
            rawFrame = _device->get_frame_data( (rs::stream)i );
            convertRsFrame2Mat( (rs::stream)i, rawFrame , &streams_mat[i] );
        }
        if (HDR_ENABLED)
        {
            cv::Mat depthShadows;
            cv::Mat depthHighlights;
            // cv::Mat temp;

            // Get depth image with low exposure(shadows):
            _device->set_option(rs::option::r200_lr_exposure, 7); 
            _device->wait_for_frames();
            rawFrame = _device->get_frame_data( rs::stream::depth );
            convertRsFrame2Mat( rs::stream::depth, rawFrame , &depthShadows );
            cvWaitKey( 50 );
            // Get depth image with high exposure(highlights):
            _device->set_option(rs::option::r200_lr_exposure, 164); 
            _device->wait_for_frames();
            rawFrame = _device->get_frame_data( rs::stream::depth );
            convertRsFrame2Mat( rs::stream::depth, rawFrame , &depthHighlights );
            cvWaitKey( 50 );
            // streams_mat[0] = streams_mat[0];
            // streams_mat[1] = depthShadows;
            // streams_mat[2] = depthHighlights;

            streams_mat[0].push_back(depthShadows);
            streams_mat[0].push_back(depthHighlights);

            _device->set_option(rs::option::r200_lr_exposure, 60);
            cvWaitKey( 50 );
        }
        last_timestamp = timestamp;
        ++num_frames;
        if(timestamp >= next_time)
        {
            currentFps = num_frames;
            num_frames = 0;
            next_time += 1000;
        }
    }
}
 
void RsCamera::convertRsFrame2Mat(rs::stream stream, const void * data, cv::Mat *outImg)
{
    int cvDataType;
    int cvDataWidth;


    rs::format streamFormat = _device->get_stream_format( stream );
    // cout << "Stream format: " << streamFormat <<endl;
    int h = _device->get_stream_height(stream);
    int w = _device->get_stream_width(stream);

    switch (streamFormat)
    {
        case rs::format::any:
            throw std::runtime_error("not a valid format");
            break;
        case rs::format::xyz32f:            //< 32 bit floating point 3D coordinates.
            cvDataType = CV_32FC3;
            cvDataWidth = 12;               /* <<<---- NOTE: needs fixed !  */
            outImg->create( h, w, cvDataType);
            memcpy(outImg->data, (uchar*)reinterpret_cast<const rs::float3 *>(data), h*w*cvDataWidth);
            break;

        /* STREAM_TYPE_DEPTH */
        case rs::format::z16:               //< 16 bit linear depth values. The depth in meters is equal to depth scale * pixel value
            // const uint16_t one_meter = (uint16_t)(1.0f / _device->get_depth_scale());

            // cvDataType = CV_16U;
            // cvDataWidth = 2;    
            // outImg->create( h, w, cvDataType);
            // memcpy(outImg->data, reinterpret_cast<const uint16_t*>(data), h*w*cvDataWidth);
            // outImg->convertTo( (* outImg), CV_8UC1, 255.0f/2.0f* _device->get_depth_scale() );
            // break;

        case rs::format::disparity16:       //< 16 bit linear disparity values. The depth in meters is equal to depth scale / pixel value
            cvDataType = CV_16U;
            cvDataWidth = 2;    
            outImg->create( h, w, cvDataType);
            memcpy(outImg->data, reinterpret_cast<const uint16_t*>(data), h*w*cvDataWidth);
            outImg->convertTo( (* outImg), CV_8UC1, 255.0f/2.0f* _device->get_depth_scale() );
            break;

        /* STREAM_TYPE_COLOR */
        case rs::format::rgb8:
        case rs::format::bgr8:
            cvDataType = CV_8UC3;
            cvDataWidth = 3;
            outImg->create( h, w, cvDataType);
            memcpy(outImg->data, (uchar*)reinterpret_cast<const uint8_t *>(data), h*w*cvDataWidth);
            cv::cvtColor( (* outImg), (* outImg), cv::COLOR_BGR2RGB );
            break;
        case rs::format::rgba8:
        case rs::format::bgra8:   
            cvDataType = CV_8UC4;
            cvDataWidth = 4;
            outImg->create( h, w, cvDataType);
            memcpy(outImg->data, data, h*w*cvDataWidth);
            break;
        case rs::format::yuyv:
        case rs::format::raw10:             //< Four 10-bit luminance values encoded into a 5-byte macropixel
        case rs::format::raw16:             //< Four 10-bit luminance filled in 16 bit pixel (6 bit unused)
            throw(0); // Not implemented
            break;
        
        /* STREAM_TYPE_IR */
        case rs::format::y8:                /* Relative IR Image */
            cvDataType = CV_8U;
            cvDataWidth = 1;
            outImg->create( h, w, cvDataType);
            memcpy(outImg->data, data, h*w*cvDataWidth);
            break;
        case rs::format::y16:               /* 16-Bit Gray Image */
            cvDataType = CV_16U;
            cvDataWidth = 2;
            outImg->create( h, w, cvDataType);
            memcpy(outImg->data, data, h*w*cvDataWidth);
            break;

        /* Monochrome Wide FOW */
        case rs::format::raw8:
            throw(0); // Not implemented
            break;

        default:
            throw std::runtime_error("The requested format is not provided by demo");
            break;
    }


    // auto points = reinterpret_cast<const rs::float3 *>(dev.get_frame_data(rs::stream::points));
    //     auto depth = reinterpret_cast<const uint16_t *>(dev.get_frame_data(rs::stream::depth));
        
    //     for(int y=0; y<depth_intrin.height; ++y)
    //     {
    //         for(int x=0; x<depth_intrin.width; ++x)
    //         {
    //             if(points->z) //if(uint16_t d = *depth++)
    //             {
    //                 //const rs::float3 point = depth_intrin.deproject({static_cast<float>(x),static_cast<float>(y)}, d*depth_scale);
    //                 glTexCoord(identical ? tex_intrin.pixel_to_texcoord({static_cast<float>(x),static_cast<float>(y)}) : tex_intrin.project_to_texcoord(extrin.transform(*points)));
    //                 glVertex(*points);
    //             }
    //             ++points;
    //         }
    //     }
}


int RsCamera::getFps()
{
    return currentFps;
}


cv::Mat* RsCamera::getMat(rs::stream stream)
{
    return &streams_mat[(int)stream];
}




Displayer::Displayer(RsCamera* rsCamera)
{
    camera = rsCamera;
}

void Displayer::initializeWindows()
{
    for (auto i : displayed_streams)
    {
        cv::namedWindow( std::to_string(  i ) , 0 );
    }
}


void Displayer::displayFps(int fps)
{
    cout << "FPS: " << fps << endl;
}


void Displayer::displayStreams()
{
    cv::Mat tmp;

    for (auto i : displayed_streams)
    {
        tmp = (* camera->getMat((rs::stream)i));

        if( (rs::stream)i == rs::stream::depth )
        {
            convertDepthMat4Display( &tmp, &tmp );
        }
        // if( (rs::stream)i == rs::stream::points )
        // {

        // }
        cv::imshow( std::to_string(i), tmp );
    }
    cvWaitKey( 1 );

}


void Displayer::displayMat(cv::Mat* frame, char* name)
{

    cv::imshow( name, (* frame) );
}


void Displayer::convertDepthMat4Display(cv::Mat* input, cv::Mat* output)
{
    input->convertTo( (* output), CV_8UC1);
    applyColorMap((* output), (* output), cv::COLORMAP_WINTER);
}



